{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08129178-9963-4c1f-a8ed-c47b99d24256",
   "metadata": {},
   "source": [
    "We want to start of by saying that this notebook is kind of all over the place, since 4 people, many of which have little coding experience. Apart from a few functions, the code is not well documented. This should have happends during the development. Never the less, we quickly added some comments above the function to guide with explaining their purpose. The code is also not really finished as there are still a lot of debug statements in the code\n",
    "\n",
    "Note. all nessecary dependencies should be installed as we do not do that in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88dce48-29f7-46ab-b5b9-d0fbe102449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all depencencies\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import jupedsim as jps\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pedpy\n",
    "from numpy.random import normal  # normal distribution of free movement speed\n",
    "from shapely import GeometryCollection, Polygon\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Polygon, GeometryCollection\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import sqlite3\n",
    "from shapely.affinity import translate\n",
    "import random\n",
    "\n",
    "\n",
    "from sociophysicsDataHandler import SociophysicsDataHandler\n",
    "import plot_basics as pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2a753-a3f8-42e9-96c4-f7dbac548f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return data from a full hour, return error if there is none.\n",
    "def fetchhour(dh, day, hour):\n",
    "    \"\"\"\n",
    "    Fetches all the data from an hour given a certain day.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns ['utc', 'tracked_object', 'x_pos', 'y_pos']\n",
    "    - day: day of the requested data in 'yyyymmdd' format\n",
    "    - hour: hour of wanted data\n",
    "\n",
    "    Returns:\n",
    "    - df: dataframe with the data of asked hour and day\n",
    "    \"\"\"\n",
    "\n",
    "    GEN_ENTRY_L1 = \"ehv/platform2.1/\"\n",
    "    GEN_ENTRY_L2 = '/EHV_Platform2.1_'\n",
    "    GEN_ENTRY_L3 = '_trajectorie.parquet' \n",
    "    path = GEN_ENTRY_L1 + day + GEN_ENTRY_L2 + day + hour + GEN_ENTRY_L3\n",
    "    \n",
    "    try:\n",
    "        dh.fetch_prorail_data_from_path(path, verbose=False)\n",
    "    except HTTPResponseError as e:\n",
    "        print(f\"Data not found for {day} hour {hour} (404)\")\n",
    "        return None\n",
    "\n",
    "    return dh.df\n",
    "\n",
    "#Fetch data from a day, filter on position and train arrival. Can be enabled/disabled\n",
    "def fetchday(dh, day, trains, filter_pos=True, filter_time=True):\n",
    "    \"\"\"\n",
    "    Fetches and combines data for all 24 hours of a given day.\n",
    "\n",
    "    Parameters:\n",
    "    - dh: Data handler object with method `fetch_prorail_data_from_path`\n",
    "    - day: Day of the requested data in 'yyyymmdd' format\n",
    "    - trains: dataframe with the train information\n",
    "    - filter_pos: option to filter position of platform\n",
    "    - filter_time: option to filter time arrival trains\n",
    "\n",
    "    Returns:\n",
    "    - df_all: Combined DataFrame with all hourly data found for that day\n",
    "    \"\"\"\n",
    "    \n",
    "    all_dfs = []\n",
    "\n",
    "    for hour in range(24):\n",
    "        hour_str = f\"{hour:02d}\"  \n",
    "        df = fetchhour(dh, day, hour_str)\n",
    "        if df is not None:\n",
    "            all_dfs.append(df)\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(f\"No data collected for {day}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "   \n",
    "    dh.df = pd.concat(all_dfs, ignore_index=True)\n",
    "    dh.df = dh.df.sort_values(by=['tracked_object', 'date_time_utc'])\n",
    "    \n",
    "    #Remove data the is not from the lower part of the platform\n",
    "    if filter_pos:\n",
    "        min_x = -2650\n",
    "        dh.df = dh.df[dh.df['x_pos'] <= min_x] \n",
    "    \n",
    "    \n",
    "    #Only ensure data in the dataset from when train arrives\n",
    "    if filter_time:\n",
    "        \n",
    "        date = pd.to_datetime(day, format = \"%Y%m%d\")\n",
    "        trains['date'] = pd.to_datetime(trains['date'])\n",
    "        train = trains[(trains['date'] == date)]\n",
    "\n",
    "        if not train.empty:\n",
    "            subsets = []\n",
    "            subsets2 = []\n",
    "            train = train[train['door_x'].notna()]\n",
    "            for arrival in train['arrival_time'].unique():\n",
    "                start = arrival\n",
    "                end = start + pd.Timedelta(minutes=1)\n",
    "                \n",
    "                subset = dh.df[(dh.df['datetime']  == start)]\n",
    "                subsets.append(subset)\n",
    "\n",
    "                subset2 = dh.df[(dh.df['datetime']  >= start) & (dh.df['datetime'] <= end)]\n",
    "                subsets2.append(subset2)\n",
    "                \n",
    "                \n",
    "            dh.df = pd.concat(subsets) if subsets else pd.DataFrame(columns=dh.df.columns)\n",
    "            dh.df2 = pd.concat(subsets2) if subsets2 else pd.DataFrame(columns=dh.df.columns)\n",
    "        else:\n",
    "            if train.empty:\n",
    "                print(\"No trains found for that date\")\n",
    "            if train['door_x'].isna().any():\n",
    "                print(\"x_door is Nan\")\n",
    "            \n",
    "            dh.df.drop(dh.df.index, inplace=True)\n",
    "            dh.df.head()\n",
    "        \n",
    "        dh.df = dh.df.sort_values(by=['tracked_object', 'date_time_utc'])\n",
    "\n",
    "    dh.df = dh.df.reset_index(drop=True)\n",
    "    return dh.df, dh.df2\n",
    "\n",
    "#Generate model parameters\n",
    "def generate_parameters(current_crowdedness=60, average_crowdedness=28):\n",
    "    crowdedness_ratio = (current_crowdedness - average_crowdedness) / average_crowdedness\n",
    "\n",
    "    crowded_weight = 0.1  # The weight of the crowdedness effect compared to the mean\n",
    "    anticipation_time = float(1.0)\n",
    "    reaction_time = 0.25\n",
    "\n",
    "    wall_buffer_distance = float(np.clip(np.random.normal(0.1, 0.01) + 0.1 * crowded_weight * crowdedness_ratio, 0.05, 0.15))\n",
    "    time_gap = float(np.clip(np.random.normal(1.06, 0.106) + 1.06 * crowded_weight * crowdedness_ratio, 0.53, 1.59))\n",
    "    range_neighbor_repulsion = float(np.clip(np.random.normal(4, 0.01) + 0.1 * crowded_weight * crowdedness_ratio, 0.05, 5))\n",
    "    strength_neighbor_repulsion = float(np.clip(np.random.normal(2, 0.8) + 8 * crowded_weight * crowdedness_ratio, 4, 12))\n",
    "\n",
    "    return {\n",
    "        \"wall_buffer_distance\": wall_buffer_distance,\n",
    "        \"anticipation_time\": anticipation_time,\n",
    "        \"reaction_time\": reaction_time,\n",
    "        \"time_gap\": time_gap,\n",
    "        \"range_neighbor_repulsion\": range_neighbor_repulsion,\n",
    "        \"strength_neighbor_repulsion\": strength_neighbor_repulsion,\n",
    "    }\n",
    "\n",
    "#Generate the map, with dynamic door allocation\n",
    "def generate_doors(train, time, door_thick=1, door_height=1.5):\n",
    "    # Define the sloped left and right wall edges\n",
    "    left_wall_start = (8.5, -5)\n",
    "    left_wall_end = (9.5, 74)\n",
    "    right_wall_start = (9.5, -5)\n",
    "    right_wall_end = (10.5, 74)\n",
    "\n",
    "    # Interpolation helper(WHY IN THIS FUNCTION???)\n",
    "    def interpolate_x(x0, y0, x1, y1, y):\n",
    "        return x0 + ((y - y0) / (y1 - y0)) * (x1 - x0)\n",
    "\n",
    "    # Filter data for the given time\n",
    "    time_filtered = train[train['arrival_time'] == time]\n",
    "    \n",
    "    door_polygons = []\n",
    "\n",
    "    for _, row in time_filtered.iterrows():\n",
    "        center_y = row[\"door_x\"] / 1000  # Convert mm to meters\n",
    "\n",
    "        y1 = center_y - door_height / 2\n",
    "        y2 = center_y + door_height / 2\n",
    "\n",
    "        # Get corresponding x-values from sloped walls\n",
    "        x1_left = interpolate_x(*left_wall_start, *left_wall_end, y1)\n",
    "        x2_left = interpolate_x(*left_wall_start, *left_wall_end, y2)\n",
    "\n",
    "        x1_right = interpolate_x(*right_wall_start, *right_wall_end, y1)\n",
    "        x2_right = interpolate_x(*right_wall_start, *right_wall_end, y2)\n",
    "\n",
    "        # Define a trapezoidal \"door\"\n",
    "        door = Polygon([\n",
    "            (x1_left, y1),\n",
    "            (x1_right, y1),\n",
    "            (x2_right, y2),\n",
    "            (x2_left, y2)\n",
    "        ])\n",
    "        door_polygons.append(door)\n",
    "\n",
    "    all_doors = unary_union(door_polygons)\n",
    "\n",
    "    # Define left and right rooms\n",
    "    left_room = Polygon([(-4, -5), (8.5, -5), (9.5, 74), (-3, 74)])\n",
    "    right_room = Polygon([(9.5, -5), (11.5, -5), (12.5, 74), (10.5, 74)])\n",
    "\n",
    "    # Define obstacles (same as before)\n",
    "    shop = Polygon([(4.5, 28.5), (1, 28.5), (1, 49.5), (4.5, 49.5)]) \n",
    "    blob = Polygon([(5, 72), (1, 72), (1, 74), (5, 74)])   \n",
    "    left_inner_wall = Polygon([(6, -5), (6, 4), (5.5, 4), (5.5, -5)]) \n",
    "    right_inner_wall = Polygon([(-1.5, -5), (-1.5, 4), (-1, 4), (-1, -5)]) \n",
    "\n",
    "    obstacles = shop.union(blob).union(left_inner_wall).union(right_inner_wall)\n",
    "\n",
    "    # Subtract obstacles from left room\n",
    "    left_room_with_holes = left_room.difference(obstacles)\n",
    "\n",
    "    # Combine geometry\n",
    "    combined_geometry = left_room_with_holes.union(right_room).union(all_doors)\n",
    "\n",
    "    walkable_area = pedpy.WalkableArea(combined_geometry)\n",
    "\n",
    "    # Plot Commeted out as of 11/06 because it keeps printing for some reasons\n",
    "    #ax = pedpy.plot_walkable_area(walkable_area=walkable_area)\n",
    "    #ax.set_aspect(\"equal\")\n",
    "\n",
    "    # Exit areas (translated forward 1.5m)\n",
    "    exit_areas = [translate(door, xoff=1.5) for door in door_polygons]\n",
    "\n",
    "    \n",
    "\n",
    "    return walkable_area, exit_areas, combined_geometry\n",
    "\n",
    "#Generate spawn location for agents\n",
    "def generate_ped_spawn(ped_spawn, time, radius = 0.25):\n",
    "    ped = ped_spawn[ped_spawn['datetime'] == time].copy()\n",
    "    ped['x_pos'] = (-ped['x_pos']) / 1000 #right scaling and conversion to meter\n",
    "    ped['y_pos'] = ped['y_pos'] / 1000 #Convert to meter\n",
    "\n",
    "    spawn_polygon = []\n",
    "    for _, row in ped.iterrows():\n",
    "        spawn_area = Point(row['x_pos'], row['y_pos']).buffer(radius)\n",
    "        spawn_polygon.append(spawn_area)\n",
    "        \n",
    "    return spawn_polygon\n",
    "\n",
    "#Spawn agents in spawn location\n",
    "def generate_agent_loc(spawn_polygons):\n",
    "    return [poly.centroid for poly in spawn_polygons]\n",
    "\n",
    "#Generate map with agents\n",
    "def plot_simulation_configuration(\n",
    "    walkable_area, spawning_area, starting_positions, exit_areas\n",
    "):\n",
    "    axes = pedpy.plot_walkable_area(walkable_area=walkable_area)\n",
    "\n",
    "    for area in spawning_area:\n",
    "        axes.fill(*area.exterior.xy, color=\"lightgrey\")\n",
    "    \n",
    "    for exit_area in exit_areas:\n",
    "        axes.fill(*exit_area.exterior.xy, color=\"indianred\")\n",
    "        \n",
    "    coords = [(p.x, p.y) for p in starting_positions]\n",
    "    axes.scatter(*zip(*coords), s=1)\n",
    "    axes.set_xlabel(\"x/m\")\n",
    "    axes.set_ylabel(\"y/m\")\n",
    "    axes.set_aspect(\"equal\")\n",
    "\n",
    "#Create the SQLite file\n",
    "def create_file(area, exitareaPed):\n",
    "\n",
    "# Save explicitly to the notebook's directory\n",
    "    trajectory_file = os.path.join(os.getcwd(), f\"bottleneck_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sqlite\")\n",
    "    trajectory_path = pathlib.Path(trajectory_file)\n",
    "\n",
    "    area = area.buffer(0)\n",
    "    try:\n",
    "        simulation = jps.Simulation(\n",
    "            model=jps.AnticipationVelocityModel(\n",
    "            #pushout_strength=0.3\n",
    "            ),\n",
    "            geometry=area,\n",
    "            trajectory_writer=jps.SqliteTrajectoryWriter(\n",
    "                output_file=pathlib.Path(trajectory_file)\n",
    "            ),\n",
    "            timestep=0.1,\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(\"Simulation creation failed due to invalid geometry:\", e)\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    os.makedirs(trajectory_path.parent, exist_ok=True)\n",
    "\n",
    "    print(f\"Saving trajectory to: {trajectory_file}\")\n",
    "\n",
    "    try:\n",
    "        exit_id1 = simulation.add_exit_stage(exitareaPed[0].exterior.coords[:-1])\n",
    "        exit_id2 = simulation.add_exit_stage(exitareaPed[1].exterior.coords[:-1])\n",
    "        exit_id3 = simulation.add_exit_stage(exitareaPed[2].exterior.coords[:-1])\n",
    "        exit_id4 = simulation.add_exit_stage(exitareaPed[3].exterior.coords[:-1])\n",
    "        exit_id5 = simulation.add_exit_stage(exitareaPed[4].exterior.coords[:-1])\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Could not add exit a stage: {e}\")\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "        \n",
    "    exit_idsleft = [exit_id1, exit_id2, exit_id3, exit_id4, exit_id5]\n",
    "\n",
    "    journey_left = jps.JourneyDescription([exit_id1, exit_id2, exit_id3, exit_id4, exit_id5])\n",
    "    journey_id_left = simulation.add_journey(journey_left)\n",
    "\n",
    "    \n",
    "\n",
    "    return simulation, trajectory_path, exit_idsleft, journey_id_left, trajectory_file\n",
    "\n",
    "\n",
    "#Spawn the agents on the map with the right model parameters and assign exit loc\n",
    "def run_sim(simulation, agents_spawn, exitareaPed, exit_idsleft, journey_id_left, time, ped_spawn ,prev_agent_count ,agent_radius = 0.18):\n",
    "    num_agents_left = len(ped_spawn[ped_spawn['datetime']== time])\n",
    "    v_distribution_left = normal(1.34, 0.05, num_agents_left)\n",
    "    #print(v_distribution_left)\n",
    "    error_add = 0\n",
    "    \n",
    "    exit_areasleft = [exitareaPed[0], exitareaPed[1], exitareaPed[2], exitareaPed[3], exitareaPed[4]]\n",
    "\n",
    "\n",
    "    #exit_idsleft = [exit_id1, exit_id2, exit_id3, exit_id4, exit_id5]\n",
    "    #exit_idsright = [exit_id6, exit_id7, exit_id8, exit_id9, exit_id10]\n",
    "\n",
    "    exit_centroids_left = [ea.centroid for ea in exit_areasleft]\n",
    "\n",
    "\n",
    "\n",
    "    ped = ped_spawn[ped_spawn['datetime'] == time].copy().reset_index(drop=True)\n",
    "    id_mapping = []\n",
    "    \n",
    "    count = 0\n",
    "    for _ in zip(agents_spawn):\n",
    "        count +=1\n",
    "\n",
    "    for pos, v0, original_id in zip(agents_spawn, v_distribution_left, ped['tracked_object']):\n",
    "        try:\n",
    "            agent_point = Point(pos)\n",
    "            closest_exit_idx = min(\n",
    "                range(len(exit_centroids_left)),\n",
    "                key=lambda i: agent_point.distance(exit_centroids_left[i])\n",
    "            )\n",
    "            parameter_dict = generate_parameters(current_crowdedness= count)\n",
    "\n",
    "    # This code will set the radius based on whether the agent is male or female\n",
    "            if (random.randint(0,1) == 0):\n",
    "            # Female condition\n",
    "                radius= float(np.clip(np.random.normal(loc=0.419, scale=0.035), 0.373, 0.539)/2)\n",
    "            # 0.469 m is the mean arm-to-spine width (radius), with an sd of 0.035 m, the maximum 0.609 m and the minimum 37.3 m\n",
    "            else:\n",
    "        # Male condition\n",
    "                radius= float(np.clip(np.random.normal(loc=0.546, scale=0.0436), 0.399, 0.636)/2)\n",
    "        # 0.546 m is the mean arm-to-spine width (radius), with an sd of 0.0436 m, the maximum  0.725 m and the minimum 0.399 m\n",
    "        # https://multisite.eos.ncsu.edu/www-ergocenter-ncsu-edu/wp-content/uploads/sites/18/2016/06/Anthropometric-Detailed-Data-Tables.pdf\n",
    "        \n",
    "            simulation.add_agent(\n",
    "                jps.AnticipationVelocityModelAgentParameters(\n",
    "                    journey_id=journey_id_left,\n",
    "                    stage_id=exit_idsleft[closest_exit_idx],\n",
    "                    position=(pos.x, pos.y),\n",
    "                    desired_speed=v0,\n",
    "                    radius = radius,\n",
    "                    **parameter_dict\n",
    "                )\n",
    "            )\n",
    "            id_mapping.append({'original_id': original_id, 'agent_id': prev_agent_count + simulation.agent_count() + error_add})\n",
    "            print(f\"Succes -> Original ID: {original_id} Simulation ID: {simulation.agent_count()}\")\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            error_add +=1\n",
    "            print(f\"{e}\")\n",
    "\n",
    "    print(\"Total agents added:\", simulation.agent_count())\n",
    "    print(id_mapping)\n",
    "\n",
    "    return id_mapping, simulation.agent_count(), error_add\n",
    "\n",
    "#Run the sim per timestep and gether the position data\n",
    "def data_gether(simulation, start_time, prev_agent_count, error_add, max_step = 45000):\n",
    "    step =0\n",
    "\n",
    "    current_time= 0\n",
    "    data = []\n",
    "    count = simulation.agent_count()\n",
    "    print(count)\n",
    "\n",
    "    if not isinstance(start_time, str):\n",
    "        start_time = str(start_time)\n",
    "    \n",
    "    utc_start_time = datetime.fromisoformat(start_time)\n",
    "\n",
    "    ######################\n",
    "    \n",
    "    print(dir(simulation))\n",
    "    agents = list(simulation.agents())\n",
    "    agent_ids = [agent.id for agent in agents]\n",
    "    print(\"Active agent IDs:\", agent_ids)\n",
    "\n",
    "\n",
    "    ###########################\n",
    "\n",
    "    while simulation.agent_count() > 0 and step < max_step:\n",
    "        #print(\"test\")\n",
    "        simulation.iterate()\n",
    "        if step % 10 == 0:\n",
    "            current_time = step * 0.01\n",
    "            #print(f\"current time: {current_time}\")\n",
    "\n",
    "            time_add = utc_start_time + timedelta(seconds=step * 0.01)\n",
    "            time_add_str = time_add.isoformat()\n",
    "\n",
    "            for i in range(prev_agent_count, prev_agent_count+count+error_add):\n",
    "                try:\n",
    "                    #print(f\"Trying agent:{i+1}\")\n",
    "                    agent = simulation.agent(i+1)\n",
    "                    data.append({\n",
    "                        'time': time_add_str,\n",
    "                        'agent_id': agent.id,\n",
    "                        'x_pos': agent.position[0],\n",
    "                        'y_pos': agent.position[1]\n",
    "                    })    \n",
    "            \n",
    "                except RuntimeError as e:\n",
    "                    #print(f\"Simulation error: {e}\")\n",
    "                    continue\n",
    "            \n",
    "\n",
    "        step += 1\n",
    "        \n",
    "    print(f\"Agents still active: {simulation.agent_count()}\")\n",
    "    not_finished = 0;\n",
    "    if simulation.agent_count() > 0:\n",
    "        not_finished = 1;\n",
    "\n",
    "    for i in range(count):\n",
    "        try:\n",
    "            agent = simulation.agent(i)\n",
    "            #print(f\"Agent {agent.id} at {agent.position}, stage_id: {agent.stage_id}\")\n",
    "        except RuntimeError as e:\n",
    "            print(\"Agent dead\")\n",
    "    return data, not_finished\n",
    "\n",
    "#Change the simulation ID to the actual ID from the data\n",
    "def merge_data(ids_table, pred_data_unmerged):\n",
    "    df = pd.DataFrame(pred_data_unmerged)\n",
    "    ids = pd.DataFrame(ids_table)\n",
    "\n",
    "    print(type(df))\n",
    "    print(type(ids))\n",
    "\n",
    "    print(df.head())\n",
    "    print(ids.head())\n",
    "    \n",
    "    pred_data_merged = pd.merge(df, ids[['agent_id', 'original_id']], on='agent_id', how='left')\n",
    "\n",
    "    pred_data_merged = pred_data_merged.rename(columns={'original_id': 'tracked_object'})\n",
    "    pred_data_merged = pred_data_merged.rename(columns={'time': 'datetime'})\n",
    "\n",
    "    return pred_data_merged\n",
    "\n",
    "#The finale pipelined function to run a single time instance \n",
    "def run_single_instance(trains, time, date, ped_spawn, total_agents = 0 ,not_print = True):\n",
    "    try:\n",
    "        walkable_area, exitareaPed, area = generate_doors(trains, time)\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Geometry error at time index {time}: {e}\")\n",
    "        print(time)\n",
    "        return pd.DataFrame()\n",
    "    spawn_poly = generate_ped_spawn(ped_spawn, time)\n",
    "    agents_spawn = generate_agent_loc(spawn_poly)\n",
    "    simulation, trajectory_path, exit_idsleft, journey_id_left, trajectory_file = create_file(area, exitareaPed)\n",
    "    if simulation is None:\n",
    "        return pd.DataFrame(), total_agents, trajectory_file\n",
    "        \n",
    "    ids_table, agent_count, error_add= run_sim(simulation, agents_spawn, exitareaPed, exit_idsleft, journey_id_left, time, ped_spawn, total_agents)\n",
    "    pred_data_unmerged, not_finished = data_gether(simulation, time, total_agents, error_add)\n",
    "    final_prediction = merge_data(ids_table, pred_data_unmerged)\n",
    "\n",
    "    current_agent_count = total_agents + agent_count + error_add\n",
    "    \n",
    "    return final_prediction, current_agent_count, trajectory_file, not_finished\n",
    "\n",
    "#Calculate the ADE for a single senario\n",
    "def calculate_ade(prediction, truth):\n",
    "    gt = truth.copy()\n",
    "    pred = prediction.copy()\n",
    "\n",
    "    gt['datetime'] = pd.to_datetime(gt['datetime'],format='ISO8601', utc = True)\n",
    "    pred['datetime'] = pd.to_datetime(pred['datetime'], format='ISO8601',utc = True)\n",
    "\n",
    "    merged = pd.merge(gt, pred, on=['tracked_object', 'datetime'], suffixes=('_gt', '_pred'))\n",
    "\n",
    "    print(\"Merged Columns:\", merged.columns)\n",
    "    \n",
    "    merged['displacement'] = np.sqrt(\n",
    "        (merged['x_pos_gt'] - merged['x_pos_pred']) ** 2 +\n",
    "        (merged['y_pos_gt'] - merged['y_pos_pred']) ** 2\n",
    "    )\n",
    "\n",
    "    ade = merged['displacement'].mean()\n",
    "    return ade\n",
    "\n",
    "#Calculate ADE from NN dataframe(obsolete)\n",
    "def calculate_ade_from_single_df(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['displacement'] = np.sqrt(\n",
    "        (df['true_x'] - df['curr_x']) ** 2 +\n",
    "        (df['true_y'] - df['curr_y']) ** 2\n",
    "    )\n",
    "    \n",
    "    ade = df['displacement'].mean()\n",
    "    return ade\n",
    "\n",
    "#Convert NN DF to the right format(obsolete)\n",
    "def convert_to(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    df = df.drop(columns=['node_type', 'pred_x', 'pred_y', 'error'])\n",
    "    df['curr_x'] = df['curr_x']/1000\n",
    "    df['curr_y'] = df['curr_y']/1000\n",
    "    df['true_x'] = df['true_x']/1000\n",
    "    df['true_y'] = df['true_y']/1000\n",
    "\n",
    "    return df\n",
    "\n",
    "#Calculate the ADE for the NN \n",
    "def calculate_ade_over_time_steps(file_names):\n",
    "    ades = []\n",
    "    for file in file_names:\n",
    "        df = convert_to(file)\n",
    "        ade = calculate_ade_from_single_df(df)\n",
    "        ades.append(ade)\n",
    "\n",
    "    overall_ade = np.mean(ades)\n",
    "    return overall_ade\n",
    "\n",
    "#Funtion for some Data analysis, abandonned due to time constained!\n",
    "def door_arrival(pred, ped, trains, datetime):\n",
    "    pred = pred.sort_values(by='datetime')\n",
    "    pred['last_post'] = pred.sort_values('datetime').groupby('tracked_object').tail(1).reset_index(drop=True) \n",
    "\n",
    "    df_last = pred.sort_values(by='datetime').groupby('tracked_object').tail(1)\n",
    "    df_last = df_last[['tracked_object', 'x_pos', 'y_pos']].rename(\n",
    "    columns={'x_pos': 'x_last', 'y_pos': 'y_last'})\n",
    "\n",
    "    df_with_last = df.merge(df_last, on='tracked_object', how='left')\n",
    "\n",
    "    df_with_last.head(20)\n",
    "    train = trains[(trains['arrival_time'] == datetime)]\n",
    "    train.head()\n",
    "\n",
    "#Added prediction of NN in 1 file\n",
    "def add_together_files(file_list):\n",
    "\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    for idx, file in enumerate(file_list, start=1):\n",
    "        df = pd.read_csv(file)\n",
    "        df = df.drop(columns=['node_type', 'pred_x', 'pred_y', 'error'])\n",
    "        df['datetime'] = idx\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "        \n",
    "#Would take a day as input and return the ADE DF for a whole day, AKA THE FINAL BOSS\n",
    "def calculate_ade_day(day):\n",
    "    dh = pb.get_SociophysDH()\n",
    "    dh.fetch_prorail_train_information()\n",
    "    trains = dh.train_information\n",
    "    ped_train_loc, ped_data = fetchday(dh, day, trains)\n",
    "    times = ped_train_loc['datetime'].unique()\n",
    "    not_finished = 0;\n",
    "\n",
    "    if ped_train_loc.empty:\n",
    "        print(f\"No data for {day}\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    print(\"Fetched data\")\n",
    "    ades= []\n",
    "    step = 0\n",
    "    nr_agents = 0\n",
    "    for time in times:\n",
    "        print(f\"Processing time step {step + 1} of {len(times)}, DateTime: {time}\")\n",
    "        step += 1\n",
    "\n",
    "        old_nr_agents = nr_agents\n",
    "        pred, nr_agents, traj_file, not_finished = run_single_instance(trains, time, day, ped_train_loc, nr_agents ,not_print= False)\n",
    "\n",
    "        not_finished += not_finished\n",
    "        simulation_nr_agents = nr_agents - old_nr_agents\n",
    "        if pred.empty:\n",
    "            ades.append({\n",
    "            'time' : time,\n",
    "            'ade'  : 0  \n",
    "            })\n",
    "\n",
    "        else:\n",
    "            \n",
    "            start_time = pd.to_datetime(pred['datetime'].iloc[0])\n",
    "            end_time = start_time + pd.Timedelta(minutes=1)\n",
    "        \n",
    "            ped = ped_data[(ped_data['datetime'] >= start_time) & (ped_data['datetime'] <= end_time)].copy()\n",
    "            ped['x_pos'] = (-ped['x_pos']) / 1000 #right scaling and conversion to meter\n",
    "            ped['y_pos'] = ped['y_pos'] / 1000\n",
    "            ade = calculate_ade(pred, ped)\n",
    "            ades.append({\n",
    "                'time' : time,\n",
    "                'ade'  : ade,\n",
    "                'nr_agents'  :  simulation_nr_agents,\n",
    "                'trajectory_file'  : traj_file\n",
    "            })\n",
    "        \n",
    "    print(f\"Amount of simulations not finished {not_finished}\")    \n",
    "    return pd.DataFrame(ades)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
